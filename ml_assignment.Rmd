---
title: "ml_assignment"
author: "Christopher Wright"
date: "February 28, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Coursera Machine Learning Assignment
The objective of this assignment is to build a model that predicts whether a given user is working out correctly with estimates of the error in our model predictions.

The model training will be done with personal activity device data that has been labeled by people while working out.

The first step is to load in the two provided datasets and set the seed for reproducibility.

```{r}
library(caret)
training = read.csv("/Users/chriswright/Desktop/pml-training.csv",header=T, na.strings=c("NA", "#DIV/0!"))
validation = read.csv("/Users/chriswright/Desktop/pml-testing.csv",header=T, na.strings=c("NA", "#DIV/0!"))
set.seed(471396)
```

Next, we look into the basic structure of the data.

```{r}
dim(training)
dim(validation)
M = sapply(training, function(x) sum(is.na(x)))
na_counts <- M[M>0]
table(na_counts)
round(unique(na_counts)/dim(training)[1],2)
```

###Data Cleaning
Many of the variables in the training set are missing significant portions of their observations. Due to the majority of the observations of these variables having missing values, I decide to throw these out. We also throw out variables that only store user specific data that isn't related to the study.

```{r}
missing = is.na(training)
na_columns = which(colSums(missing) > 15000)
training = training[, -na_columns]
training = training[,-c(1:8)]
dim(training)

validation = validation[, -na_columns]
validation = validation[,-c(1:8)]
```

###Data Partitions
We next create the data partitions. Because I plan on using random forests to do my predictions, I do not bother with cross validation. It is estimated internally during training via the oob estimate.
```{r}
inTrain <- createDataPartition(y=training$classe, p=0.80, list=FALSE)
training_data <- training[inTrain,]
testing_data <- training[-inTrain,]
```
###Model Training and Testing
The random forest is trained against the training data and used to predict the testing data classe outcomes.
```{r}
library(randomForest)
model = randomForest(classe~., data=training_data, ntree=200)
model
pred <- predict(model, newdata=testing_data)
confusionMatrix(pred, testing_data$classe)
```
###Discussion
The results of the model claim a low(<1%) OOB estimate. This is an accurate estimate of out of sample error. Additionally, the model is performant on the testing set data.